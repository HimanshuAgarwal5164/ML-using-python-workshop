{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sklearn module has some pre-determined datasets inside the module.\n",
    "#So, instead of cleaning and using other datasets, we are using some in-built datasets for practise.\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = digits.data\n",
    "y = digits.target\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, we can import the cross_val_score module for cross validation of data\n",
    "#Also,import KNeighborsClassifier module to implement Nearest Neighbour Classification.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an object of KNeighborsClassifier as-\n",
    "k = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99652778, 0.97916667, 0.97560976, 0.98954704, 0.97212544])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We calculate Cross-Validation score as-      cross_val_score(k,x_train,y_train,cv=5)\n",
    "#The cross_val_score() method takes 4 parameters as- KNearestNeighborsClassifier object(k),\n",
    "#                                                  - x_train,y_train (i.e.training dataset),\n",
    "#                                                  - cv parameter(represents number of folds during cross validation)\n",
    "\n",
    "cross_val_score(k,x_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see, the cross validation scores for my dataset goes from around 0.9721 to 0.9965\n",
    "#This is pretty great (97% to 99% accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are specific modules to use in order to select my cv parameter for the best accuracy\n",
    "#The 2 modules we can use for selecting our cv are- 'KFold' and 'RepeatedStratifiedKFold'\n",
    "from sklearn.model_selection import KFold,RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97916667, 0.99305556, 0.98611111, 0.98611111, 0.97916667,\n",
       "       0.98611111, 0.99305556, 0.99300699, 0.95104895, 0.98601399])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KFold takes parameters as n_splits=10,shuffle=True,random_state=42\n",
    "cross_val_score(k,x_train,y_train,cv=KFold(n_splits=10,shuffle=True,random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using KFold increased my efficiency as 0.9791 to 0.9930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98611111, 0.98611111, 0.97916667, 0.98611111, 0.99305556,\n",
       "       0.97222222, 1.        , 0.98601399, 0.98601399, 0.97902098,\n",
       "       0.97916667, 0.97916667, 0.99305556, 0.98611111, 0.99305556,\n",
       "       0.97916667, 0.99305556, 0.96503497, 1.        , 1.        ,\n",
       "       0.97916667, 0.96527778, 0.99305556, 0.99305556, 0.97222222,\n",
       "       1.        , 0.97916667, 1.        , 0.98601399, 0.99300699,\n",
       "       0.97916667, 0.98611111, 0.99305556, 0.98611111, 0.99305556,\n",
       "       0.98611111, 1.        , 0.97902098, 0.97902098, 0.97902098,\n",
       "       1.        , 0.97916667, 0.99305556, 0.98611111, 0.98611111,\n",
       "       0.97916667, 0.97916667, 0.98601399, 0.97202797, 0.98601399,\n",
       "       0.98611111, 0.98611111, 0.97222222, 0.97916667, 1.        ,\n",
       "       0.98611111, 0.97916667, 0.99300699, 0.96503497, 1.        ,\n",
       "       0.99305556, 0.97916667, 0.99305556, 0.97916667, 0.99305556,\n",
       "       0.97916667, 0.99305556, 0.98601399, 0.99300699, 0.97202797,\n",
       "       1.        , 0.97916667, 0.99305556, 0.99305556, 1.        ,\n",
       "       1.        , 0.97916667, 0.97902098, 0.98601399, 0.97202797,\n",
       "       1.        , 0.97916667, 0.99305556, 0.96527778, 1.        ,\n",
       "       0.97916667, 0.97916667, 0.98601399, 1.        , 0.97202797,\n",
       "       0.99305556, 0.96527778, 0.97916667, 0.97222222, 1.        ,\n",
       "       0.98611111, 1.        , 0.99300699, 0.97902098, 0.98601399])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RepeatedStratifiedKFold takes parameters as n_splits=10,n_repeats=10,random_state=42\n",
    "cross_val_score(k,x_train,y_train,cv=RepeatedStratifiedKFold(n_splits=10,n_repeats=10,random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see RepeatedStratifiedKFold has increased my accuracy to a greatpoint such that we could see few 1 above\n",
    "#Which means 100% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's see the SVM module for Support Vector Machines(another way to do multiclassification algorithm)\n",
    "#Also we'd look at Grid Searches using GridSearchCV module that is used to do automatic efficient cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
